OmicSelector2: A Next-Generation Multi-Omics Biomarker Discovery Platform
Advances in sequencing and imaging generate multi-omics datasets (genomics, transcriptomics, proteomics, metabolomics, radiomics, etc.) that capture complex tumor biology. By combining these layers, AI/ML can uncover hidden relationships and predictive biomarkers not evident in any single dataset[1]. For example, one review notes that “by effectively combining different types of omics data, AI techniques can unveil hidden connections, detect biomarkers, and improve disease prediction”[1]. Integrating genomics, transcriptomics, proteomics and other modalities provides complementary views of tumor mechanisms, revealing intricate regulatory networks[2]. However, such data are extremely high-dimensional (“curse of dimensionality”), so feature selection is critical to remove irrelevant or redundant variables, improve model performance, and avoid overfitting[3]. In practice, machine learning has already shown great promise in extracting predictive signals from high-dimensional multi-omics data[4].
Review of OmicSelector 1.0 and Rationale for OmicSelector2
The original OmicSelector (v1) was an R-based platform (Docker container with web GUI) designed for transcriptomic feature selection and biomarker signature ranking. It offered dozens of methods (filter, wrapper, embedded) and then “benchmarked” each feature set by cross-validation with multiple classifiers[5]. In that workflow, candidate signatures were evaluated by their average predictive performance (e.g. ROC AUC) across models to identify top biomarkers[5]. While innovative, OmicSelector1 had limitations: it was built in R (limiting wider adoption), lacked modern scalable ML frameworks (e.g. recent Python libraries), and did not focus on interpretability or integration of diverse data types (e.g. single-cell, radiomics). Many original methods (MDL-based filters, bespoke wrappers, extensive SMOTE variants) are now dated. OmicSelector2 will modernize this pipeline in Python: adopting the most effective feature-selection algorithms, adding interpretability (SHAP/LIME, pathway analysis), and supporting multi-omics (bulk RNA-seq, single-cell, WES, radiomics) with a new web UI for data upload and analysis.
State-of-the-Art Feature Selection Methods
To handle diverse oncology datasets, OmicSelector2 will implement a curated set of advanced feature-selection approaches and deprecate obsolete ones. We will support three classes of methods:
•	Filter methods (independent of any classifier): statistical tests and ranking. For example, differential expression tests (t-test, ANOVA, fold-change) with multiple-testing corrections to rank genes. Selecting features with significant p-values or largest effect sizes is a fast first step. We also include information-based filters (e.g. mutual information, mRMR) and correlation filters to remove redundant features. While simple, filters risk ignoring feature interactions; they are best used as a first-pass or in combination with other methods[3].
•	Wrapper methods (model-based search): Recursive Feature Elimination (RFE) with modern classifiers (linear SVM, Random Forest, XGBoost) to iteratively select important features. For example, an RFE loop could fit an SVM or tree and remove lowest-importance features until a stopping criterion. We will include Boruta (a Random Forest–based consensus wrapper) and genetic- or heuristic-search algorithms that iteratively evaluate subsets by model accuracy. These methods directly optimize predictive performance at the cost of greater computation. We also allow user-supplied ML models to rank features. The old OmicSelector “classloop” (ensemble of SVM, LDA, RF) is replaced by a more direct ranking approach using single (or ensembled) classifiers. Methods like fwrap, fcfs or MDL-discretization (CorrSF_MDL, SU_MDL) from the original are deprecated in favor of standard wrappers and embedded methods.
•	Embedded methods (built into model training): Regularized models such as LASSO or Elastic Net logistic regression naturally shrink coefficients, selecting a sparse set of genes. Tree-based models (Random Forest, XGBoost, LightGBM, CatBoost) provide feature importance scores (gain, permutation importance). We will include these and allow permutation-importance calculations to find features critical for accuracy. Stability-selection (bootstrap LASSO) can improve robustness. Dimensionality-reduction methods (PCA, Autoencoders) are not feature selection per se, but we may allow them for visualization or feature embedding. Recent advances like deep learning-based selection (e.g. Concrete Autoencoders, L0-regularized nets) can be considered for future extension. Crucially, we will integrate hybrid workflows: for instance, a correlation filter followed by an RFE wrapper, as recommended by Perez-Riverol et al.[6]. In summary, we focus on methods with demonstrated utility in high-dimensional bio-data and drop niche or redundant filters from OmicSelector1.
Importantly, no single FS method works best on all data[7]. The literature shows that combining multiple FS strategies can yield robust signatures: one study built cancer gene signatures by taking the intersection of the top features from several methods[7]. OmicSelector2 will allow the user to run multiple selectors in parallel and compare results, or even take consensus features. Any new method (e.g. Boruta, mRMR) will be optional so advanced users can customize their pipeline.
Multi-Omics Data Integration and Signature Discovery
A key aim is to support integrated multi-omics analysis. OmicSelector2 will allow users to upload separate omics datasets (e.g. bulk RNA-seq count tables, SNP/variant calls from WES, single-cell expression matrices, radiomic feature tables). We will provide preprocessing routines (normalization, variance filtering) and the ability to align samples across modalities. Users can select subsets of data (e.g. tumor vs. control), and then apply joint FS strategies.
Deep learning methods have shown promise for multi-omics integration, but many remain at proof-of-concept stage[8]. For example, graph-based networks (MOGONET) and multimodal transformers can fuse different omics, but they often overfit small samples[9]. Recent work in hepatocellular carcinoma illustrates this: combining RFE with a transformer improved results, and the authors stressed “the importance of adapting or extending deep learning models to support robust feature selection, especially for multi-omics data with limited sample size”[9]. We will thus include basic support for multi-view FS: e.g. concatenating feature sets with modality-specific scaling, or multi-step selection (select on one omic then on another). We also plan to integrate with known multi-omic factor analysis tools (e.g. MOFA, iCluster) that find shared latent features if applicable.
After FS, OmicSelector2 will enter its signature benchmarking phase (inspired by OmicSelector1). Each candidate signature (set of features) will be evaluated by training predictive models on the data. We will implement a suite of classifiers (e.g. logistic regression, RF, SVM, neural nets) with cross-validation or external validation. The goal is to compute performance metrics (accuracy, ROC-AUC, etc.) for each signature. As in OmicSelector1, we average performance across models or folds to rank the signatures[5]. The platform will output a ranked list of candidate biomarkers (gene sets, radiomic feature sets, etc.) with their performance. This helps users select the most promising signature for further study. By supporting multi-omics, we may discover biomarker panels that span data types (e.g. combining a few genes with imaging features) – a true radiogenomic signature.
Radiomics and Imaging Features
Radiomics (quantitative imaging) will be explicitly supported. Radiomics “extracts high-dimensional features from medical images (MRI, CT, PET) to quantify tumor heterogeneity[10].” These features include texture patterns, shape descriptors, intensity statistics, etc., which have been used to differentiate benign vs. malignant lesions and predict treatment response[10]. In the sarcoma literature, radiomics-AI pipelines are well-developed (using RF, CNN, etc.) but notably lack integration of molecular data[11]. OmicSelector2 will allow users to upload pre-computed radiomic feature sets (e.g. output from PyRadiomics) alongside genomic data. The platform will treat radiomic features like any other assay: the user can include them in FS and modeling. Although true tri-modal integration is rare[11], our flexible design will enable exploratory fusion of imaging and omics data. We may also incorporate advanced network models (attention or graph-based) as the radiogenomic field evolves[12].
Model Interpretability and Explainability
In clinical biomarker work, interpretability is crucial. OmicSelector2 will embed explainability tools to help users understand why certain features are predictive. We will integrate SHAP (SHapley Additive exPlanations) values for any fitted model, yielding global feature importance and per-sample explanations. For example, recent multi-cancer platelet studies used SHAP to rank genes, provide local explanations, and identify gene-level patterns[13]. OmicSelector2 will compute a consensus SHAP score across models (e.g. weighted by model AUC) so that important biomarkers are consistently highlighted. We will also offer alternatives like LIME or partial-dependence plots as needed. In summary, after training a classifier, the UI will present intuitive visualizations (bar charts of feature importance, dependence plots, decision trees, etc.) so researchers can validate that selected biomarkers make biological sense. This addresses calls for transparency in medical AI: interpretable biomarker models build trust and help avoid spurious results[13].
Technical Architecture and Web Interface
OmicSelector2 will be implemented in Python 3 for broad compatibility and access to modern libraries. Core dependencies will include scikit-learn, XGBoost/LightGBM/CatBoost, PyTorch or TensorFlow/Keras for neural nets, and pandas/numpy for data handling. The web UI could use Dash (Plotly) or Streamlit, which allow building rich data apps in Python. Dash is powerful for complex dashboards, custom callbacks and authentication; Streamlit is very fast for prototyping and has built-in support for widgets and file uploads. Either framework can deliver a browser-based interface where users upload CSV/Excel (or HDF5/AnnData for scRNA), configure analysis steps, and view results.
Key UI features include: file upload, data summary (basic stats, missing values), selection of FS methods (checkbox list), parameter inputs (e.g. number of features, CV folds), and launch of the pipeline. Progress and logs should be displayed. Results pages will show selected signatures, cross-validation metrics, and visualizations (boxplots, heatmaps, ROC curves). We will use Plotly for interactive figures and possibly Shapash or similar libraries for interpretability visuals. Authentication (user accounts) and secure data handling will be essential since biomedical data is sensitive; TLS encryption and on-disk encryption can be added.
For reproducibility and deployment, we will containerize the app with Docker (leveraging GPUs if using deep learning). A Docker image (or Kubernetes cluster) will encapsulate all software (including a fixed Python environment). This follows the approach of OmicSelector1, which used Docker for stability[5]. Testing will include unit tests of each module and integration tests of the web app. Continuous Integration (GitHub Actions or similar) will run analysis on sample datasets to ensure results are consistent. Ultimately, the platform can be deployed on a university server or cloud (AWS/GCP), exposing an HTTPS service. Data persistence (e.g. job queues, history) should respect privacy; we may implement automatic data deletion after analysis or user-controlled clearing.
Development Plan (Agentic Task List)
1.	Requirement Gathering & Architecture: Define use cases (bulk RNA-seq, WES, scRNA, radiomics). Sketch system design (modules: Data IO, FS algorithms, ML models, UI, storage). Choose libraries (e.g. scikit-learn, PyTorch).
2.	Set Up Repository and Environment: Initialize a Git repository with branches. Configure Python environment (e.g. use Poetry or Conda). Establish coding standards and testing frameworks (pytest).
3.	Data Import & Preprocessing: Implement data loaders for generic tabular data (support CSV, TSV, Excel). Add special parsers if needed (e.g. MAF for mutations, AnnData for scRNA). Include common preprocessing (normalization, log-transform, filtering zero-variance features).
4.	Feature Selection Module: Develop wrappers for each FS method:
5.	Filters: t-test, ANOVA, fold-change, mutual-information (mRMR).
6.	Wrappers: RFE with SVM and RF, Boruta (via boruta_py), ReliefF (for multiclass).
7.	Embedded: LASSO/ElasticNet (via scikit-learn), tree-based feature importance.
Each method should take a dataset and return a ranked feature list (or set). Unit tests will verify method performance on toy data.
8.	Modeling & Benchmarking Module: Implement classification/regression models (SVM, Random Forest, Logistic, k-NN, XGBoost, a simple neural net). Create a pipeline to evaluate each signature: train each model with cross-validation (stratified where needed), compute metrics (accuracy, AUC, F1, etc.). Aggregate results (e.g. average AUC across models) for each feature set. Use scikit-learn’s pipeline and cross_val_score for consistency. Also include an option for ensemble/meta-learner if time permits.
9.	Interpretability Integration: Integrate the SHAP library: after fitting a model on the full training data, compute SHAP values for features. Provide functions to generate global importance plots and local explanations for individual samples. Develop a “consensus SHAP” method: e.g. run SHAP on each classifier and take a weighted average of importances. Also support LIME for any model if requested.
10.	Web UI Development: Prototype the web interface. If using Dash: design pages for data upload, analysis configuration, and results. If Streamlit: use sidebar widgets for FS/method selection. Ensure the UI can display interactive Plotly charts for data preview and results. Implement callbacks or commands so that when a user clicks “Run Analysis”, the backend modules are invoked. Ensure file uploads are validated (e.g. check file format, size).
11.	Backend & Integration: Connect the UI frontend to the backend functions (FS and modeling). Possibly use Celery or threading to run long tasks asynchronously while updating status. Ensure that multiple users or sessions do not interfere.
12.	Testing & Validation: Create test cases using synthetic and real-world datasets (e.g. a public cancer dataset). Verify that known markers are recovered, and that metrics match expectations. Perform performance profiling: optimize any slow routines (e.g. use sparse matrices, limit hyperparameter tuning).
13.	Containerization: Write a Dockerfile that installs all dependencies (Python libs, ML frameworks). Ensure it can utilize a GPU if available (CUDA libraries for PyTorch/TensorFlow). Test that the container reproduces results on example data. Provide example docker run commands in documentation.
14.	Documentation and User Guide: Write detailed docs in Markdown (as “Claude.md”). Include examples of input formatting, interpretation of results, and command references. Create a tutorial dataset and walkthrough. Document how to extend the tool (add new FS methods, models).
15.	Deployment and Maintenance: Deploy the app internally or on cloud for beta testing. Monitor usage and fix any bugs. Plan for future extensions: adding new FS methods (e.g. permutation tests, deep autoencoders), or supporting additional data types (imaging volumes, EHR data). Establish a feedback channel for user requests and issues.
Throughout development, we will adhere to best practices: modular code, thorough logging, version control, and continuous integration. Data privacy and ethical considerations will be baked in: patient data will be kept secure, and model explanations will be required for any clinical claims. In summary, OmicSelector2 will be a comprehensive, Python-based toolkit enabling researchers to upload their own multi-omics data, select and benchmark biomarker signatures with state-of-the-art methods, and obtain interpretable models[13][5].
Sources: OmicSelector1 documentation[5]; multi-omics FS and integration reviews[1][4][2]; scRNA-seq FS benchmarks[14]; FS algorithms surveys[3][7]; radiomics-AI review[11][10]; ML interpretability studies[13].
 
[1] [8] Challenges in AI-driven multi-omics data analysis for Oncology: Addressing dimensionality, sparsity, transparency and ethical considerations | Request PDF
https://www.researchgate.net/publication/394268359_Challenges_in_AI-driven_multi-omics_data_analysis_for_Oncology_Addressing_dimensionality_sparsity_transparency_and_ethical_considerations
[2] [4] Machine learning and multi-omics integration: advancing cardiovascular translational research and clinical practice | Journal of Translational Medicine | Full Text
https://translational-medicine.biomedcentral.com/articles/10.1186/s12967-025-06425-2
[3] [6] Accurate and fast feature selection workflow for high-dimensional omics data | PLOS One
https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0189875
[5] OmicSelector - a package for biomarker selection based on high-throughput experiments. • OmicSelector
https://kstawiski.github.io/OmicSelector/
[7] Comparison of five supervised feature selection algorithms leading to top features and gene signatures from multi-omics data in cancer | BMC Bioinformatics | Full Text
https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-022-04678-y
[9] Multi-Omics Feature Selection to Identify Biomarkers for Hepatocellular Carcinoma
https://www.mdpi.com/2218-1989/15/9/575
[10] [11] [12] Frontiers | Integrating radiomics, artificial intelligence, and molecular signatures in bone and soft tissue tumors: advances in diagnosis and prognostication
https://www.frontiersin.org/journals/oncology/articles/10.3389/fonc.2025.1613133/full
[13] Interpretable Multi-Cancer Early Detection Using SHAP-Based Machine Learning on Tumor-Educated Platelet RNA - PubMed
https://pubmed.ncbi.nlm.nih.gov/40941703/
[14] Feature selection methods affect the performance of scRNA-seq data integration and querying | Nature Methods
https://www.nature.com/articles/s41592-025-02624-3?error=cookies_not_supported&code=4450ad5a-a683-41ad-9edd-58387f53785a
