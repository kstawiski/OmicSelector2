{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Complete Biomarker Discovery Workflow with Google Drive\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kstawiski/OmicSelector2/blob/main/examples/07_complete_workflow.ipynb)\n",
    "\n",
    "**End-to-End Biomarker Discovery Pipeline** - From raw data to publication-ready results!\n",
    "\n",
    "**What This Notebook Covers:**\n",
    "1. ðŸ“¥ Data loading and quality control\n",
    "2. ðŸ§¹ Preprocessing and normalization\n",
    "3. âœ‚ï¸ Proper data splitting\n",
    "4. ðŸ” Multiple feature selection methods\n",
    "5. ðŸŽ¯ Stability selection\n",
    "6. ðŸ“Š Signature benchmarking\n",
    "7. ðŸ¤– Model training and optimization\n",
    "8. ðŸ“ˆ Comprehensive evaluation\n",
    "9. ðŸ§  Model interpretation (SHAP)\n",
    "10. ðŸ“ Publication-ready results\n",
    "\n",
    "**All results automatically saved to Google Drive!**\n",
    "\n",
    "**Estimated Time**: 45-60 minutes  \n",
    "**Level**: Advanced (but fully guided!)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OmicSelector2 and dependencies\n",
    "print(\"ðŸ“¦ Installing OmicSelector2 and dependencies...\\n\")\n",
    "!pip install -q git+https://github.com/kstawiski/OmicSelector2.git\n",
    "!pip install -q shap matplotlib-venn openpyxl\n",
    "print(\"âœ… Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "drive.mount('/content/drive', force_remount=False)\n",
    "\n",
    "# Create timestamped project directory\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "BASE_DIR = '/content/drive/MyDrive/OmicSelector2'\n",
    "PROJECT_DIR = f'{BASE_DIR}/projects/workflow_{timestamp}'\n",
    "\n",
    "# Create comprehensive folder structure\n",
    "folders = {\n",
    "    'data/raw': f'{PROJECT_DIR}/data/raw',\n",
    "    'data/processed': f'{PROJECT_DIR}/data/processed',\n",
    "    'data/splits': f'{PROJECT_DIR}/data/splits',\n",
    "    'results/qc': f'{PROJECT_DIR}/results/qc',\n",
    "    'results/features': f'{PROJECT_DIR}/results/features',\n",
    "    'results/models': f'{PROJECT_DIR}/results/models',\n",
    "    'results/evaluation': f'{PROJECT_DIR}/results/evaluation',\n",
    "    'plots/qc': f'{PROJECT_DIR}/plots/qc',\n",
    "    'plots/features': f'{PROJECT_DIR}/plots/features',\n",
    "    'plots/performance': f'{PROJECT_DIR}/plots/performance',\n",
    "    'plots/interpretation': f'{PROJECT_DIR}/plots/interpretation',\n",
    "    'models': f'{PROJECT_DIR}/models',\n",
    "    'checkpoints': f'{PROJECT_DIR}/checkpoints',\n",
    "    'final_report': f'{PROJECT_DIR}/final_report'\n",
    "}\n",
    "\n",
    "for name, path in folders.items():\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Google Drive mounted and project structure created!\")\n",
    "print(f\"\\nðŸ“‚ Project directory: {PROJECT_DIR}\")\n",
    "print(f\"\\nAll results will be saved here automatically.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    confusion_matrix, classification_report,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# OmicSelector2 imports\n",
    "from omicselector2.features.classical import (\n",
    "    LassoSelector, ElasticNetSelector, RandomForestSelector,\n",
    "    MRMRSelector, BorutaSelector\n",
    ")\n",
    "from omicselector2.features.ensemble import EnsembleSelector\n",
    "from omicselector2.features.stability import StabilitySelector\n",
    "from omicselector2.models.classical import RandomForestClassifier, XGBoostClassifier\n",
    "from omicselector2.training.benchmarking import Benchmarker\n",
    "from omicselector2.training.cross_validation import StratifiedKFoldSplitter\n",
    "\n",
    "# Visualization settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 1: Data Loading & Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ§¬ Generating realistic biomarker dataset...\\n\")\n",
    "\n",
    "# Create realistic RNA-seq-like dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 300\n",
    "n_genes = 1000\n",
    "n_informative = 30\n",
    "\n",
    "# Generate expression data with biological structure\n",
    "X_raw = np.random.negative_binomial(n=10, p=0.3, size=(n_samples, n_genes)).astype(float)\n",
    "X_raw += np.random.rand(n_samples, n_genes) * 10  # Add continuous variation\n",
    "\n",
    "# Create outcome based on informative genes\n",
    "true_coef = np.zeros(n_genes)\n",
    "true_coef[:n_informative] = np.random.randn(n_informative) * 2\n",
    "linear_combination = X_raw @ true_coef\n",
    "probs = 1 / (1 + np.exp(-linear_combination / np.std(linear_combination)))\n",
    "y = (probs > 0.5).astype(int)\n",
    "\n",
    "# Add some noise\n",
    "flip_idx = np.random.choice(n_samples, size=int(n_samples * 0.05), replace=False)\n",
    "y[flip_idx] = 1 - y[flip_idx]\n",
    "\n",
    "# Create DataFrame\n",
    "gene_names = [f\"GENE_{i:04d}\" for i in range(n_genes)]\n",
    "sample_ids = [f\"SAMPLE_{i:03d}\" for i in range(n_samples)]\n",
    "X_raw = pd.DataFrame(X_raw, columns=gene_names, index=sample_ids)\n",
    "\n",
    "# Clinical data\n",
    "clinical = pd.DataFrame({\n",
    "    'sample_id': sample_ids,\n",
    "    'age': np.random.randint(40, 80, n_samples),\n",
    "    'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "    'stage': np.random.choice(['I', 'II', 'III', 'IV'], n_samples, p=[0.2, 0.3, 0.3, 0.2]),\n",
    "    'response': y,\n",
    "    'batch': np.random.choice(['Batch_A', 'Batch_B'], n_samples)\n",
    "})\n",
    "\n",
    "# Add some missing values\n",
    "missing_mask = np.random.random(X_raw.shape) < 0.005\n",
    "X_raw = X_raw.mask(missing_mask)\n",
    "\n",
    "# Save raw data\n",
    "X_raw.to_csv(f\"{folders['data/raw']}/gene_expression_raw.csv\")\n",
    "clinical.to_csv(f\"{folders['data/raw']}/clinical_data.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Dataset created and saved to Drive!\")\n",
    "print(f\"\\nðŸ“Š Dataset characteristics:\")\n",
    "print(f\"   â€¢ Samples: {X_raw.shape[0]}\")\n",
    "print(f\"   â€¢ Genes: {X_raw.shape[1]}\")\n",
    "print(f\"   â€¢ Truly informative genes: {n_informative}\")\n",
    "print(f\"   â€¢ Missing values: {X_raw.isna().sum().sum()}\")\n",
    "print(f\"   â€¢ Class distribution: {clinical['response'].value_counts().to_dict()}\")\n",
    "\n",
    "display(X_raw.iloc[:5, :5])\n",
    "display(clinical.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” Step 2: Quality Control & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ” Quality Control Analysis\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# QC metrics\n",
    "lib_sizes = X_raw.sum(axis=1)\n",
    "gene_means = X_raw.mean(axis=0)\n",
    "gene_vars = X_raw.var(axis=0)\n",
    "missing_per_gene = X_raw.isna().sum() / len(X_raw) * 100\n",
    "\n",
    "print(f\"ðŸ“Š Sample-level QC:\")\n",
    "print(f\"   â€¢ Mean library size: {lib_sizes.mean():,.0f}\")\n",
    "print(f\"   â€¢ Median library size: {lib_sizes.median():,.0f}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Gene-level QC:\")\n",
    "print(f\"   â€¢ Genes with >5% missing: {(missing_per_gene > 5).sum()}\")\n",
    "print(f\"   â€¢ Low variance genes (bottom 10%): {(gene_vars < gene_vars.quantile(0.1)).sum()}\")\n",
    "\n",
    "# Clean data\n",
    "print(f\"\\nðŸ§¹ Cleaning data...\")\n",
    "X_clean = X_raw.copy()\n",
    "\n",
    "#Remove low variance genes\n",
    "var_threshold = gene_vars.quantile(0.1)\n",
    "X_clean = X_clean.loc[:, gene_vars >= var_threshold]\n",
    "print(f\"   âœ“ Removed {(gene_vars < var_threshold).sum()} low-variance genes\")\n",
    "\n",
    "# Impute missing values\n",
    "X_clean = X_clean.fillna(X_clean.median())\n",
    "print(f\"   âœ“ Imputed missing values with gene medians\")\n",
    "\n",
    "# Normalize: Log2 + Z-score\n",
    "X_log = np.log2(X_clean + 1)\n",
    "scaler = StandardScaler()\n",
    "X_normalized = pd.DataFrame(\n",
    "    scaler.fit_transform(X_log),\n",
    "    columns=X_log.columns,\n",
    "    index=X_log.index\n",
    ")\n",
    "print(f\"   âœ“ Normalized (log2 + z-score)\")\n",
    "\n",
    "print(f\"\\nâœ… After preprocessing: {X_normalized.shape}\")\n",
    "\n",
    "# Save processed data\n",
    "X_normalized.to_csv(f\"{folders['data/processed']}/gene_expression_normalized.csv\")\n",
    "print(f\"ðŸ’¾ Saved to: {folders['data/processed']}/gene_expression_normalized.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ Step 3: Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ‚ï¸ Splitting data (60% train / 20% val / 20% test)\\n\")\n",
    "\n",
    "# First split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_normalized, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]} samples\")\n",
    "print(f\"Val:   {X_val.shape[0]} samples\")\n",
    "print(f\"Test:  {X_test.shape[0]} samples\")\n",
    "\n",
    "# Save splits\n",
    "for name, (X_split, y_split) in zip(\n",
    "    ['train', 'val', 'test'],\n",
    "    [(X_train, y_train), (X_val, y_val), (X_test, y_test)]\n",
    "):\n",
    "    X_split.to_csv(f\"{folders['data/splits']}/X_{name}.csv\")\n",
    "    pd.DataFrame({'sample_id': X_split.index, 'response': y_split}).to_csv(\n",
    "        f\"{folders['data/splits']}/y_{name}.csv\", index=False\n",
    "    )\n",
    "\n",
    "print(f\"\\nðŸ’¾ Splits saved to: {folders['data/splits']}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 4: Feature Selection - Multiple Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ” Running multiple feature selection methods...\\n\")\n",
    "\n",
    "signatures = {}\n",
    "selectors_dict = {}\n",
    "\n",
    "# 1. Lasso\n",
    "print(\"1/6 Running Lasso...\")\n",
    "lasso = LassoSelector(alpha=0.01, task='classification', n_features_to_select=50, random_state=42)\n",
    "lasso.fit(X_train, y_train)\n",
    "signatures['Lasso_50'] = lasso.selected_features_\n",
    "selectors_dict['Lasso'] = lasso\n",
    "\n",
    "# 2. Elastic Net\n",
    "print(\"2/6 Running Elastic Net...\")\n",
    "enet = ElasticNetSelector(alpha=0.01, l1_ratio=0.7, task='classification', n_features_to_select=50, random_state=42)\n",
    "enet.fit(X_train, y_train)\n",
    "signatures['ElasticNet_50'] = enet.selected_features_\n",
    "selectors_dict['ElasticNet'] = enet\n",
    "\n",
    "# 3. Random Forest\n",
    "print(\"3/6 Running Random Forest...\")\n",
    "rf = RandomForestSelector(n_estimators=100, task='classification', n_features_to_select=50, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "signatures['RandomForest_50'] = rf.selected_features_\n",
    "selectors_dict['RandomForest'] = rf\n",
    "\n",
    "# 4. mRMR\n",
    "print(\"4/6 Running mRMR...\")\n",
    "mrmr = MRMRSelector(n_features_to_select=50, random_state=42)\n",
    "mrmr.fit(X_train, y_train)\n",
    "signatures['mRMR_50'] = mrmr.selected_features_\n",
    "selectors_dict['mRMR'] = mrmr\n",
    "\n",
    "# 5. Ensemble\n",
    "print(\"5/6 Running Ensemble...\")\n",
    "ensemble = EnsembleSelector(\n",
    "    selectors=[lasso, enet, rf, mrmr],\n",
    "    strategy='soft_voting',\n",
    "    n_features_to_select=40\n",
    ")\n",
    "ensemble.fit(X_train, y_train)\n",
    "signatures['Ensemble_40'] = ensemble.selected_features_\n",
    "selectors_dict['Ensemble'] = ensemble\n",
    "\n",
    "# 6. Stability Selection\n",
    "print(\"6/6 Running Stability Selection (this takes longer...)\")\n",
    "stability = StabilitySelector(\n",
    "    base_selector=RandomForestSelector(n_estimators=50, task='classification'),\n",
    "    n_bootstraps=100,\n",
    "    threshold=0.6,\n",
    "    sample_fraction=0.8,\n",
    "    n_features_to_select=40,\n",
    "    random_state=42,\n",
    "    checkpoint_dir=folders['checkpoints'],\n",
    "    checkpoint_every=20\n",
    ")\n",
    "stability.fit(X_train, y_train)\n",
    "signatures['Stability_40'] = stability.selected_features_\n",
    "selectors_dict['Stability'] = stability\n",
    "\n",
    "print(f\"\\nâœ… All feature selection methods complete!\")\n",
    "print(f\"\\nðŸ“Š Signatures generated:\")\n",
    "for name, feats in signatures.items():\n",
    "    overlap_with_truth = len(set(feats) & set(gene_names[:n_informative]))\n",
    "    print(f\"   â€¢ {name}: {len(feats)} features ({overlap_with_truth}/{n_informative} true positives)\")\n",
    "\n",
    "# Save signatures\n",
    "for name, feats in signatures.items():\n",
    "    pd.DataFrame({'gene': feats}).to_csv(\n",
    "        f\"{folders['results/features']}/signature_{name}.csv\", index=False\n",
    "    )\n",
    "\n",
    "print(f\"\\nðŸ’¾ Signatures saved to: {folders['results/features']}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 5: Signature Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Benchmarking all signatures...\\n\")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBoostClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Benchmark\n",
    "benchmarker = Benchmarker(\n",
    "    models=models,\n",
    "    cv_strategy=StratifiedKFoldSplitter(n_splits=5, shuffle=True, random_state=42),\n",
    "    metrics=['accuracy', 'auc', 'f1']\n",
    ")\n",
    "\n",
    "benchmark_results = benchmarker.benchmark_signatures(\n",
    "    X_train, y_train, signatures, verbose=True\n",
    ")\n",
    "\n",
    "# Get summary\n",
    "summary_df = benchmarker.get_summary_table()\n",
    "print(\"\\nðŸ“Š Benchmark Results:\")\n",
    "print(\"=\"*70)\n",
    "display(summary_df)\n",
    "\n",
    "# Save results\n",
    "summary_df.to_csv(f\"{folders['results/evaluation']}/benchmark_results.csv\", index=False)\n",
    "print(f\"\\nðŸ’¾ Benchmark results saved!\")\n",
    "\n",
    "# Find best signature\n",
    "best_sig = summary_df.groupby('signature')['cv_auc'].mean().idxmax()\n",
    "print(f\"\\nðŸ† Best signature: {best_sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– Step 6: Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ðŸ¤– Training final model with {best_sig}...\\n\")\n",
    "\n",
    "# Get best signature features\n",
    "best_features = signatures[best_sig]\n",
    "X_train_best = X_train[best_features]\n",
    "X_val_best = X_val[best_features]\n",
    "X_test_best = X_test[best_features]\n",
    "\n",
    "# Train on train + val\n",
    "X_trainval = pd.concat([X_train_best, X_val_best])\n",
    "y_trainval = np.concatenate([y_train, y_val])\n",
    "\n",
    "final_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "final_model.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = final_model.predict(X_test_best)\n",
    "y_pred_proba = final_model.predict_proba(X_test_best)[:, 1]\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"âœ… Final Model Performance (Test Set):\")\n",
    "print(f\"   â€¢ AUC:      {test_auc:.4f}\")\n",
    "print(f\"   â€¢ Accuracy: {test_acc:.4f}\")\n",
    "print(f\"   â€¢ F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save model\n",
    "model_path = f\"{folders['models']}/final_model.pkl\"\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': final_model,\n",
    "        'features': best_features,\n",
    "        'signature_name': best_sig,\n",
    "        'test_auc': test_auc\n",
    "    }, f)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Step 7: Comprehensive Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“ˆ Creating comprehensive evaluation plots...\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Confusion Matrix', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('True')\n",
    "axes[0, 0].set_xlabel('Predicted')\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "axes[0, 1].plot(fpr, tpr, linewidth=2, label=f'AUC = {test_auc:.3f}')\n",
    "axes[0, 1].plot([0, 1], [0, 1], 'k--')\n",
    "axes[0, 1].set_xlabel('FPR')\n",
    "axes[0, 1].set_ylabel('TPR')\n",
    "axes[0, 1].set_title('ROC Curve', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "axes[0, 2].plot(recall, precision, linewidth=2)\n",
    "axes[0, 2].set_xlabel('Recall')\n",
    "axes[0, 2].set_ylabel('Precision')\n",
    "axes[0, 2].set_title('Precision-Recall Curve', fontweight='bold')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Feature importance\n",
    "importances = pd.DataFrame({\n",
    "    'feature': best_features,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "axes[1, 0].barh(range(len(importances)), importances['importance'])\n",
    "axes[1, 0].set_yticks(range(len(importances)))\n",
    "axes[1, 0].set_yticklabels(importances['feature'])\n",
    "axes[1, 0].invert_yaxis()\n",
    "axes[1, 0].set_title('Top 20 Features', fontweight='bold')\n",
    "\n",
    "# 5. Prediction distribution\n",
    "axes[1, 1].hist(y_pred_proba[y_test==0], bins=20, alpha=0.6, label='Class 0')\n",
    "axes[1, 1].hist(y_pred_proba[y_test==1], bins=20, alpha=0.6, label='Class 1')\n",
    "axes[1, 1].set_xlabel('Predicted Probability')\n",
    "axes[1, 1].set_title('Prediction Distribution', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# 6. Signature comparison\n",
    "sig_aucs = summary_df.groupby('signature')['cv_auc'].mean().sort_values(ascending=False)\n",
    "axes[1, 2].barh(range(len(sig_aucs)), sig_aucs.values)\n",
    "axes[1, 2].set_yticks(range(len(sig_aucs)))\n",
    "axes[1, 2].set_yticklabels(sig_aucs.index)\n",
    "axes[1, 2].invert_yaxis()\n",
    "axes[1, 2].set_xlabel('Mean CV AUC')\n",
    "axes[1, 2].set_title('Signature Performance', fontweight='bold')\n",
    "axes[1, 2].axvline(sig_aucs[best_sig], color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "eval_path = f\"{folders['plots/performance']}/comprehensive_evaluation.png\"\n",
    "plt.savefig(eval_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"ðŸ’¾ Evaluation plots saved to: {eval_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Step 8: Model Interpretation with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ§  Computing SHAP values for interpretation...\\n\")\n",
    "\n",
    "# Compute SHAP\n",
    "explainer = shap.TreeExplainer(final_model.model if hasattr(final_model, 'model') else final_model)\n",
    "shap_values = explainer.shap_values(X_test_best)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[1]\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test_best, plot_type='bar', show=False, max_display=20)\n",
    "plt.tight_layout()\n",
    "shap_path = f\"{folders['plots/interpretation']}/shap_summary.png\"\n",
    "plt.savefig(shap_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"ðŸ’¾ SHAP plots saved to: {folders['plots/interpretation']}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Step 9: Generate Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive final report\n",
    "report = f\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "           COMPLETE BIOMARKER DISCOVERY REPORT - OmicSelector2\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Project Directory: {PROJECT_DIR}\n",
    "\n",
    "1. DATASET INFORMATION\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Total Samples:                    {n_samples}\n",
    "Total Genes (original):           {n_genes}\n",
    "Genes (after QC):                 {X_normalized.shape[1]}\n",
    "Training Samples:                 {X_train.shape[0]}\n",
    "Validation Samples:               {X_val.shape[0]}\n",
    "Test Samples:                     {X_test.shape[0]}\n",
    "\n",
    "2. FEATURE SELECTION RESULTS\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Methods Applied:                  {len(signatures)}\n",
    "Signatures Generated:\n",
    "{chr(10).join([f'  â€¢ {name}: {len(feats)} features' for name, feats in signatures.items()])}\n",
    "\n",
    "3. BENCHMARKING RESULTS (5-Fold CV)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Best Signature:                   {best_sig}\n",
    "Best CV AUC:                      {summary_df.groupby('signature')['cv_auc'].mean().max():.4f}\n",
    "\n",
    "4. FINAL MODEL PERFORMANCE (Hold-out Test Set)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Model:                            Random Forest (200 trees)\n",
    "Features Used:                    {len(best_features)}\n",
    "Test AUC:                         {test_auc:.4f}\n",
    "Test Accuracy:                    {test_acc:.4f}\n",
    "Test F1 Score:                    {test_f1:.4f}\n",
    "\n",
    "5. TOP 10 BIOMARKER GENES\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "{chr(10).join([f'{i+1:2d}. {gene}' for i, gene in enumerate(importances.head(10)['feature'])])}\n",
    "\n",
    "6. FILES SAVED TO GOOGLE DRIVE\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Raw Data:                         {folders['data/raw']}/\n",
    "Processed Data:                   {folders['data/processed']}/\n",
    "Data Splits:                      {folders['data/splits']}/\n",
    "Feature Signatures:               {folders['results/features']}/\n",
    "Benchmark Results:                {folders['results/evaluation']}/\n",
    "Final Model:                      {folders['models']}/final_model.pkl\n",
    "Plots:                            {folders['plots']}/\n",
    "\n",
    "7. KEY FINDINGS & RECOMMENDATIONS\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "âœ“ Completed end-to-end biomarker discovery pipeline\n",
    "âœ“ {len(signatures)} feature selection methods compared\n",
    "âœ“ {best_sig} showed best cross-validation performance\n",
    "âœ“ Final model achieves {test_auc:.3f} AUC on independent test set\n",
    "âœ“ {len(best_features)} genes selected as final biomarker signature\n",
    "âœ“ All results saved persistently to Google Drive\n",
    "\n",
    "NEXT STEPS:\n",
    "â€¢ Validate signature in independent cohort\n",
    "â€¢ Perform pathway enrichment analysis\n",
    "â€¢ Consider experimental validation of top genes\n",
    "â€¢ Review biological literature for candidate genes\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report\n",
    "report_path = f\"{folders['final_report']}/FINAL_REPORT.txt\"\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Save selected genes with all info\n",
    "final_signature = pd.DataFrame({\n",
    "    'rank': range(1, len(best_features) + 1),\n",
    "    'gene': best_features,\n",
    "    'importance': final_model.feature_importances_,\n",
    "    'is_true_positive': [gene in gene_names[:n_informative] for gene in best_features]\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "final_signature.to_csv(f\"{folders['final_report']}/final_signature.csv\", index=False)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Final report saved to: {report_path}\")\n",
    "print(f\"ðŸ’¾ Final signature saved to: {folders['final_report']}/final_signature.csv\")\n",
    "print(f\"\\nâœ… COMPLETE WORKFLOW FINISHED!\")\n",
    "print(f\"\\nðŸ“‚ All results available at: {PROJECT_DIR}\")\n",
    "print(f\"\\nYou can access these files from Google Drive on any device!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Summary & Next Steps\n",
    "\n",
    "### What You've Accomplished ðŸŽ‰\n",
    "\n",
    "âœ… **Data QC & Preprocessing**: Cleaned and normalized gene expression data  \n",
    "âœ… **Proper Data Splitting**: Train/val/test splits preventing data leakage  \n",
    "âœ… **Multiple Feature Selection**: Compared 6 different methods  \n",
    "âœ… **Stability Selection**: Bootstrap-based robust feature identification  \n",
    "âœ… **Signature Benchmarking**: Systematic comparison across models  \n",
    "âœ… **Model Training**: Optimized final model on best signature  \n",
    "âœ… **Comprehensive Evaluation**: ROC, PR, confusion matrix, calibration  \n",
    "âœ… **Model Interpretation**: SHAP values for explainability  \n",
    "âœ… **Publication-Ready Results**: All saved to Google Drive  \n",
    "\n",
    "### Your Google Drive Project Structure\n",
    "\n",
    "```\n",
    "MyDrive/OmicSelector2/projects/workflow_[timestamp]/\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ raw/                  # Original data\n",
    "â”‚   â”œâ”€â”€ processed/            # Normalized data\n",
    "â”‚   â””â”€â”€ splits/               # Train/val/test splits\n",
    "â”œâ”€â”€ results/\n",
    "â”‚   â”œâ”€â”€ qc/                   # Quality control reports\n",
    "â”‚   â”œâ”€â”€ features/             # All feature signatures\n",
    "â”‚   â”œâ”€â”€ models/               # Model performance\n",
    "â”‚   â””â”€â”€ evaluation/           # Benchmark results\n",
    "â”œâ”€â”€ models/\n",
    "â”‚   â””â”€â”€ final_model.pkl       # Trained model (ready to deploy!)\n",
    "â”œâ”€â”€ plots/                    # All visualizations\n",
    "â”œâ”€â”€ checkpoints/              # For long-running analyses\n",
    "â””â”€â”€ final_report/\n",
    "    â”œâ”€â”€ FINAL_REPORT.txt      # Complete analysis report\n",
    "    â””â”€â”€ final_signature.csv   # Selected biomarker genes\n",
    "```\n",
    "\n",
    "### Publication Checklist âœï¸\n",
    "\n",
    "- [ ] Validate signature in independent cohort\n",
    "- [ ] Pathway enrichment analysis (KEGG, GO)\n",
    "- [ ] Literature review of candidate genes\n",
    "- [ ] Statistical comparison with published signatures\n",
    "- [ ] Clinical correlation analysis\n",
    "- [ ] Write methods section (all parameters saved!)\n",
    "\n",
    "### ðŸ”¬ Real Data Next Steps\n",
    "\n",
    "To use this workflow with your own data:\n",
    "\n",
    "1. **Upload your data** to Drive:\n",
    "   ```python\n",
    "   # Upload to: MyDrive/OmicSelector2/projects/your_project/data/raw/\n",
    "   ```\n",
    "\n",
    "2. **Modify Step 1** to load your data:\n",
    "   ```python\n",
    "   X_raw = pd.read_csv(\"path/to/your/data.csv\", index_col=0)\n",
    "   clinical = pd.read_csv(\"path/to/clinical.csv\")\n",
    "   y = clinical['outcome'].values\n",
    "   ```\n",
    "\n",
    "3. **Adjust parameters** based on your data size:\n",
    "   - `n_features_to_select`: 10-100 depending on sample size\n",
    "   - `n_bootstraps`: 50-200 for stability selection\n",
    "   - `cv_folds`: 3-10 depending on sample size\n",
    "\n",
    "4. **Run the entire notebook!**\n",
    "\n",
    "### ðŸ’¡ Pro Tips\n",
    "\n",
    "- **Collaboration**: Share your project folder with team members\n",
    "- **Version Control**: Create dated project folders for each analysis\n",
    "- **Checkpoints**: Long analyses save progress automatically\n",
    "- **Reproducibility**: All parameters and random seeds saved\n",
    "- **Documentation**: Reports include all analysis details\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations on completing the full biomarker discovery pipeline! ðŸ§¬ðŸ”¬ðŸŽ‰**\n",
    "\n",
    "*You're now ready to discover clinically relevant biomarkers with OmicSelector2!*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
