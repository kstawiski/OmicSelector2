{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udd0d Model Interpretation & Explainability with Google Drive\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kstawiski/OmicSelector2/blob/main/examples/06_model_interpretation.ipynb)\n",
    "\n",
    "**What You'll Learn:**\n",
    "- \ud83d\udcca Comprehensive model evaluation metrics\n",
    "- \ud83c\udfaf SHAP values for feature importance\n",
    "- \ud83d\udcc8 ROC curves, PR curves, calibration plots\n",
    "- \ud83e\udde0 Feature interactions and dependencies\n",
    "- \ud83d\udcbe Save all interpretation results to Drive\n",
    "\n",
    "**Estimated Time**: 25-30 minutes  \n",
    "**Prerequisites**: Basic ML model training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "!pip install -q git+https://github.com/kstawiski/OmicSelector2.git\n",
    "!pip install -q shap lime\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive', force_remount=False)\n",
    "BASE_DIR = '/content/drive/MyDrive/OmicSelector2'\n",
    "os.makedirs(f'{BASE_DIR}/results/interpretation', exist_ok=True)\n",
    "os.makedirs(f'{BASE_DIR}/plots/interpretation', exist_ok=True)\n",
    "\n",
    "print(f'\u2705 Drive mounted: {BASE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    confusion_matrix, classification_report,\n",
    "    calibration_curve\n",
    ")\n",
    "import pickle\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print('\u2705 Libraries loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Load Data and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or create data\n",
    "np.random.seed(42)\n",
    "X, y = make_classification(\n",
    "    n_samples=500, n_features=50, n_informative=20,\n",
    "    n_redundant=10, random_state=42\n",
    ")\n",
    "X = pd.DataFrame(X, columns=[f'GENE_{i:04d}' for i in range(X.shape[1])])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print('\ud83e\udd16 Training Random Forest...')\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'\u2705 Model trained! Test AUC: {auc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Comprehensive Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\ud83d\udcca Model Evaluation\\n' + '='*60 + '\\n')\n",
    "\n",
    "# Classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=['Non-responder', 'Responder']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create comprehensive plot\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0],\n",
    "            xticklabels=['Non-responder', 'Responder'],\n",
    "            yticklabels=['Non-responder', 'Responder'])\n",
    "axes[0, 0].set_ylabel('True Label')\n",
    "axes[0, 0].set_xlabel('Predicted Label')\n",
    "axes[0, 0].set_title('Confusion Matrix', fontweight='bold')\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "axes[0, 1].plot(fpr, tpr, linewidth=2, label=f'AUC = {auc:.3f}')\n",
    "axes[0, 1].plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "axes[0, 1].set_xlabel('False Positive Rate')\n",
    "axes[0, 1].set_ylabel('True Positive Rate')\n",
    "axes[0, 1].set_title('ROC Curve', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "axes[0, 2].plot(recall, precision, linewidth=2)\n",
    "axes[0, 2].set_xlabel('Recall')\n",
    "axes[0, 2].set_ylabel('Precision')\n",
    "axes[0, 2].set_title('Precision-Recall Curve', fontweight='bold')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prediction distribution\n",
    "axes[1, 0].hist(y_pred_proba[y_test==0], bins=30, alpha=0.6, label='Class 0', edgecolor='black')\n",
    "axes[1, 0].hist(y_pred_proba[y_test==1], bins=30, alpha=0.6, label='Class 1', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Predicted Probability')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Prediction Distribution', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 5. Calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_pred_proba, n_bins=10)\n",
    "axes[1, 1].plot(prob_pred, prob_true, marker='o', linewidth=2, label='Model')\n",
    "axes[1, 1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Perfect')\n",
    "axes[1, 1].set_xlabel('Predicted Probability')\n",
    "axes[1, 1].set_ylabel('True Probability')\n",
    "axes[1, 1].set_title('Calibration Curve', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Feature importance (top 20)\n",
    "importances = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "axes[1, 2].barh(range(len(importances)), importances['importance'], color='steelblue')\n",
    "axes[1, 2].set_yticks(range(len(importances)))\n",
    "axes[1, 2].set_yticklabels(importances['feature'])\n",
    "axes[1, 2].invert_yaxis()\n",
    "axes[1, 2].set_xlabel('Importance')\n",
    "axes[1, 2].set_title('Top 20 Feature Importances', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "eval_path = f'{BASE_DIR}/plots/interpretation/comprehensive_evaluation.png'\n",
    "plt.savefig(eval_path, dpi=300, bbox_inches='tight')\n",
    "print(f'\\n\ud83d\udcbe Evaluation plots saved to: {eval_path}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf SHAP Values for Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\ud83c\udfaf Computing SHAP values...')\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# For binary classification, take class 1\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[1]\n",
    "\n",
    "print('\u2705 SHAP values computed!\\n')\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, plot_type='bar', show=False, max_display=20)\n",
    "plt.tight_layout()\n",
    "shap_bar_path = f'{BASE_DIR}/plots/interpretation/shap_summary_bar.png'\n",
    "plt.savefig(shap_bar_path, dpi=300, bbox_inches='tight')\n",
    "print(f'\ud83d\udcbe SHAP bar plot saved to: {shap_bar_path}')\n",
    "plt.show()\n",
    "\n",
    "# Detailed beeswarm plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, show=False, max_display=20)\n",
    "plt.tight_layout()\n",
    "shap_bee_path = f'{BASE_DIR}/plots/interpretation/shap_summary_beeswarm.png'\n",
    "plt.savefig(shap_bee_path, dpi=300, bbox_inches='tight')\n",
    "print(f'\ud83d\udcbe SHAP beeswarm plot saved to: {shap_bee_path}')\n",
    "plt.show()\n",
    "\n",
    "# Save SHAP values\n",
    "shap_df = pd.DataFrame(shap_values, columns=X_test.columns)\n",
    "shap_path = f'{BASE_DIR}/results/interpretation/shap_values.csv'\n",
    "shap_df.to_csv(shap_path, index=False)\n",
    "print(f'\ud83d\udcbe SHAP values saved to: {shap_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcdd Create Interpretation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "report = f\"\"\"\n",
    "\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "    MODEL INTERPRETATION REPORT - OmicSelector2\n",
    "\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\n",
    "Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Location: {BASE_DIR}\n",
    "\n",
    "MODEL INFORMATION\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "Model Type:           Random Forest Classifier\n",
    "Number of Trees:      100\n",
    "Features Used:        {X_train.shape[1]}\n",
    "Training Samples:     {X_train.shape[0]}\n",
    "Test Samples:         {X_test.shape[0]}\n",
    "\n",
    "PERFORMANCE METRICS\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "Accuracy:             {accuracy_score(y_test, y_pred):.4f}\n",
    "Precision:            {precision_score(y_test, y_pred):.4f}\n",
    "Recall:               {recall_score(y_test, y_pred):.4f}\n",
    "F1 Score:             {f1_score(y_test, y_pred):.4f}\n",
    "AUC-ROC:              {auc:.4f}\n",
    "\n",
    "TOP 10 IMPORTANT FEATURES (SHAP)\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "{chr(10).join([f'{i+1:2d}. {feat}' for i, feat in enumerate(importances.head(10)['feature'])])}\n",
    "\n",
    "CONFUSION MATRIX\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "                 Predicted\n",
    "                 Neg    Pos\n",
    "Actual Neg      {cm[0, 0]:4d}   {cm[0, 1]:4d}\n",
    "       Pos      {cm[1, 0]:4d}   {cm[1, 1]:4d}\n",
    "\n",
    "FILES SAVED TO GOOGLE DRIVE\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "Model:                {BASE_DIR}/models/\n",
    "SHAP Values:          {BASE_DIR}/results/interpretation/\n",
    "Plots:                {BASE_DIR}/plots/interpretation/\n",
    "\n",
    "KEY INSIGHTS\n",
    "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "\u2713 Model shows {'excellent' if auc > 0.9 else 'good' if auc > 0.8 else 'moderate'} discriminative ability (AUC = {auc:.3f})\n",
    "\u2713 SHAP analysis reveals feature importance and interactions\n",
    "\u2713 All interpretation results saved to Google Drive\n",
    "\u2713 Model {'is well-calibrated' if abs(prob_true[-1] - prob_pred[-1]) < 0.1 else 'may need calibration'}\n",
    "\n",
    "\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "report_path = f'{BASE_DIR}/results/interpretation/interpretation_report.txt'\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f'\\n\ud83d\udcbe Report saved to: {report_path}')\n",
    "print(f'\\n\u2705 All interpretation results saved to Google Drive!')\n",
    "print(f'\ud83d\udcc2 Access at: {BASE_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf93 Summary\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "\u2705 **Comprehensive Evaluation**: ROC, PR, calibration curves  \n",
    "\u2705 **SHAP Values**: Feature importance and interactions  \n",
    "\u2705 **Model Diagnostics**: Confusion matrix, prediction distributions  \n",
    "\u2705 **Drive Integration**: All results saved automatically  \n",
    "\n",
    "### Why Model Interpretation Matters\n",
    "\n",
    "1. **Trust**: Understand how models make predictions\n",
    "2. **Debugging**: Identify potential issues\n",
    "3. **Biological Insights**: Discover meaningful patterns\n",
    "4. **Clinical Translation**: Explain to stakeholders\n",
    "5. **Regulatory**: FDA/EMA require explainability\n",
    "\n",
    "### \ud83d\udcda Next Steps\n",
    "\n",
    "- **[07_complete_workflow.ipynb](07_complete_workflow.ipynb)** - Full end-to-end pipeline\n",
    "\n",
    "---\n",
    "\n",
    "**Explainable AI = trustworthy biomarkers! \ud83e\uddec\ud83d\udd2c**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}